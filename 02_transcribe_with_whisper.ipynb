{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "177cf636",
=======
   "id": "40d3520b-cdfc-4808-b6cd-1427ea879160",
>>>>>>> 5625b42e9c7fc7f9541b0395f102fa36508b6ee4
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'write_vtt' from 'whisper.utils' (/Volumes/Users/matu/.local/share/virtualenvs/whisper-n0mNy6m5/lib/python3.9/site-packages/whisper/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwhisper\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m write_vtt\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'write_vtt' from 'whisper.utils' (/Volumes/Users/matu/.local/share/virtualenvs/whisper-n0mNy6m5/lib/python3.9/site-packages/whisper/utils.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import whisper\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from whisper.utils import write_vtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "bf0ed8f1",
=======
   "id": "1728b728-8d9e-465e-a6c2-018ee346e406",
>>>>>>> 5625b42e9c7fc7f9541b0395f102fa36508b6ee4
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "1229e193",
=======
   "id": "ed24b53b-c0b8-45e1-809b-ee8ca9a8b155",
>>>>>>> 5625b42e9c7fc7f9541b0395f102fa36508b6ee4
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2.88G/2.88G [10:41<00:00, 4.81MiB/s]\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"large\").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "464b9e2d",
=======
   "id": "61e1c281-bc21-4193-a45c-9878558d96fd",
>>>>>>> 5625b42e9c7fc7f9541b0395f102fa36508b6ee4
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_files(model, files):\n",
    "    print(f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
    "          f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
    "         )\n",
    "    for input_file in tqdm(files):\n",
    "        print(f\"Transcribing file: {input_file}\")\n",
    "        result = model.transcribe(str(input_file), verbose=False, language=\"en\", )\n",
    "\n",
    "        # save TXT\n",
    "        with open(input_file.with_suffix(\".txt\"), \"w\", encoding=\"utf-8\") as txt:\n",
    "            print(result[\"text\"], file=txt)\n",
    "\n",
    "        # save VTT\n",
    "        with open(input_file.with_suffix(\".vtt\"), \"w\", encoding=\"utf-8\") as vtt:\n",
    "            write_vtt(result[\"segments\"], file=vtt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "c5d48078",
=======
   "id": "ec4975ce-8cc4-4f00-8839-0daee1ce2c80",
>>>>>>> 5625b42e9c7fc7f9541b0395f102fa36508b6ee4
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(Path(\"videos\").glob(\"*.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "9f116bc1",
=======
   "id": "c5d44a53-51d9-4f35-a899-8aabc2abd0c1",
>>>>>>> 5625b42e9c7fc7f9541b0395f102fa36508b6ee4
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is English-only and has 762,320,896 parameters.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d25d5831c704f208c0e64c79be1b43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing file: videos/_Dianthus video - Final.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Users/matu/.local/share/virtualenvs/whisper-n0mNy6m5/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n",
      "  0%|                                                                                                          | 0/15033 [00:00<?, ?frames/s]\u001b[A\n",
      " 19%|██████████████████▎                                                                            | 2898/15033 [06:58<29:11,  6.93frames/s]\u001b[A\n",
      " 36%|██████████████████████████████████▍                                                            | 5440/15033 [15:30<28:08,  5.68frames/s]\u001b[A\n",
      " 52%|█████████████████████████████████████████████████▎                                             | 7812/15033 [23:40<22:45,  5.29frames/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████████████▍                            | 10472/15033 [33:01<15:02,  5.05frames/s]\u001b[A\n",
      " 88%|██████████████████████████████████████████████████████████████████████████████████▋           | 13232/15033 [46:50<07:05,  4.23frames/s]\u001b[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████▎        | 13642/15033 [51:00<06:07,  3.79frames/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 15033/15033 [52:55<00:00,  4.73frames/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "transcribe_files(model, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d265bf9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
<<<<<<< HEAD
   "name": "whisper"
=======
   "name": "python3"
>>>>>>> 5625b42e9c7fc7f9541b0395f102fa36508b6ee4
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
